{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-to-SQL Production System - Final Version\n",
    "\n",
    "**Team:** Eba Adisu (UGR/2749/14), Mati Milkessa (UGR/0949/14), Nahom Garefo (UGR/6739/14)\n",
    "\n",
    "**Target:** 35-50% Exact Match on Spider Dataset\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1: Install Dependencies\n",
    "!pip install -q transformers>=4.35.0 datasets>=2.14.0 accelerate>=0.24.0\n",
    "!pip install -q torch sentencepiece sqlparse pandas numpy tqdm scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Imports and System Check\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"TEXT-TO-SQL PRODUCTION SYSTEM\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    GPU_NAME = torch.cuda.get_device_name(0)\n",
    "    GPU_MEM = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"GPU: {GPU_NAME} ({GPU_MEM:.1f} GB)\")\n",
    "    \n",
    "    if GPU_MEM >= 15:\n",
    "        MODEL_NAME = \"google-t5/t5-base\"\n",
    "        print(f\"\\nUsing: T5-Base (expect 35-45% accuracy)\")\n",
    "    else:\n",
    "        MODEL_NAME = \"google-t5/t5-small\"\n",
    "        print(f\"\\nUsing: T5-Small (expect 20-30% accuracy)\")\n",
    "else:\n",
    "    MODEL_NAME = \"google-t5/t5-small\"\n",
    "    print(\"\\nWARNING: No GPU detected!\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Spider Dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "print(\"Loading Spider dataset...\")\n",
    "\n",
    "dataset = None\n",
    "for source in [\"xlangai/spider\", \"spider\"]:\n",
    "    try:\n",
    "        print(f\"  Trying {source}...\")\n",
    "        dataset = load_dataset(source)\n",
    "        print(f\"  Success!\")\n",
    "        break\n",
    "    except:\n",
    "        print(f\"  Failed\")\n",
    "\n",
    "if dataset is None:\n",
    "    raise Exception(\"Could not load Spider dataset. Download manually from https://yale-lily.github.io/spider\")\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Train: {len(dataset['train'])} examples\")\n",
    "print(f\"  Validation: {len(dataset['validation'])} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Schema Serialization Function\n",
    "def serialize_schema(example):\n",
    "    \"\"\"\n",
    "    Convert Spider schema to text format.\n",
    "    Format: \"table1: col1, col2 | table2: col1, col2\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        table_names = example.get('db_table_names', [])\n",
    "        column_names = example.get('db_column_names', [])\n",
    "        column_types = example.get('db_column_types', [])\n",
    "        \n",
    "        # Group columns by table\n",
    "        table_cols = defaultdict(list)\n",
    "        \n",
    "        for idx, col_info in enumerate(column_names):\n",
    "            if not isinstance(col_info, (list, tuple)) or len(col_info) < 2:\n",
    "                continue\n",
    "            \n",
    "            table_idx = col_info[0]\n",
    "            col_name = col_info[1]\n",
    "            \n",
    "            # Skip wildcard column\n",
    "            if table_idx == -1:\n",
    "                continue\n",
    "            \n",
    "            # Skip invalid table index\n",
    "            if table_idx >= len(table_names):\n",
    "                continue\n",
    "            \n",
    "            table_name = table_names[table_idx]\n",
    "            col_str = str(col_name).lower()\n",
    "            \n",
    "            # Add type if available\n",
    "            if idx < len(column_types) and column_types[idx]:\n",
    "                col_str += f\" ({column_types[idx]})\"\n",
    "            \n",
    "            table_cols[table_name].append(col_str)\n",
    "        \n",
    "        # Build schema string\n",
    "        if table_cols:\n",
    "            parts = [f\"{tbl}: {', '.join(cols)}\" for tbl, cols in table_cols.items()]\n",
    "            return \" | \".join(parts)\n",
    "        else:\n",
    "            return example.get('db_id', 'database')\n",
    "    \n",
    "    except Exception:\n",
    "        return example.get('db_id', 'database')\n",
    "\n",
    "print(\"Schema serialization function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Preprocessing Function\n",
    "def preprocess_example(example):\n",
    "    \"\"\"\n",
    "    Convert Spider example to model input/output format.\n",
    "    \"\"\"\n",
    "    question = str(example.get('question', '')).strip()\n",
    "    sql = str(example.get('query', '')).strip()\n",
    "    schema = serialize_schema(example)\n",
    "    \n",
    "    # Format input\n",
    "    input_text = f\"translate to SQL: {question} | schema: {schema}\"\n",
    "    \n",
    "    # Normalize SQL whitespace\n",
    "    target_text = re.sub(r'\\s+', ' ', sql).strip()\n",
    "    \n",
    "    return {\n",
    "        \"input_text\": input_text,\n",
    "        \"target_text\": target_text\n",
    "    }\n",
    "\n",
    "print(\"Preprocessing dataset...\")\n",
    "processed = dataset.map(\n",
    "    preprocess_example,\n",
    "    num_proc=4,\n",
    "    desc=\"Preprocessing\"\n",
    ")\n",
    "\n",
    "print(f\"\\nPreprocessing complete!\")\n",
    "print(f\"\\nSample input:\")\n",
    "print(f\"  {processed['train'][0]['input_text'][:150]}...\")\n",
    "print(f\"\\nSample target:\")\n",
    "print(f\"  {processed['train'][0]['target_text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Load Tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print(f\"Loading tokenizer: {MODEL_NAME}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "MAX_INPUT_LEN = 512\n",
    "MAX_TARGET_LEN = 256\n",
    "\n",
    "print(f\"  Vocab size: {len(tokenizer)}\")\n",
    "print(f\"  Max input: {MAX_INPUT_LEN} tokens\")\n",
    "print(f\"  Max target: {MAX_TARGET_LEN} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Tokenization\n",
    "def tokenize_fn(examples):\n",
    "    \"\"\"\n",
    "    Tokenize inputs and targets.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        examples[\"input_text\"],\n",
    "        max_length=MAX_INPUT_LEN,\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    \n",
    "    targets = tokenizer(\n",
    "        text_target=examples[\"target_text\"],\n",
    "        max_length=MAX_TARGET_LEN,\n",
    "        truncation=True,\n",
    "        padding=False\n",
    "    )\n",
    "    \n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "print(\"Tokenizing dataset...\")\n",
    "\n",
    "# Get columns to remove (all original columns)\n",
    "cols_to_remove = processed['train'].column_names\n",
    "\n",
    "tokenized = processed.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=cols_to_remove,\n",
    "    desc=\"Tokenizing\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTokenization complete!\")\n",
    "print(f\"  Final columns: {tokenized['train'].column_names}\")\n",
    "print(f\"  Sample input_ids length: {len(tokenized['train'][0]['input_ids'])}\")\n",
    "print(f\"  Sample labels length: {len(tokenized['train'][0]['labels'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Load Model\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "print(f\"Loading model: {MODEL_NAME}\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Enable memory optimization\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "print(f\"  Parameters: {model.num_parameters():,}\")\n",
    "print(f\"  Gradient checkpointing: Enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Training Setup\n",
    "from transformers import (\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "\n",
    "# Data collator\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer=tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=-100,\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./text2sql_model\",\n",
    "    \n",
    "    # Epochs and batch\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    \n",
    "    # Optimizer\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    warmup_ratio=0.1,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    \n",
    "    # Training optimization\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    gradient_checkpointing=True,\n",
    "    label_smoothing_factor=0.1,\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"exact_match\",\n",
    "    greater_is_better=True,\n",
    "    \n",
    "    # Generation\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=MAX_TARGET_LEN,\n",
    "    generation_num_beams=4,\n",
    "    \n",
    "    # Logging\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    \n",
    "    # System\n",
    "    dataloader_num_workers=2,\n",
    "    seed=42,\n",
    ")\n",
    "\n",
    "print(\"Training configuration:\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size} x {training_args.gradient_accumulation_steps} = {training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"  FP16: {training_args.fp16}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Metrics Function (Safe)\n",
    "VOCAB_SIZE = len(tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    Compute exact match accuracy with overflow protection.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # CRITICAL: Clip predictions to valid vocab range to prevent overflow\n",
    "    predictions = np.clip(predictions, 0, VOCAB_SIZE - 1)\n",
    "    \n",
    "    # Decode predictions\n",
    "    try:\n",
    "        pred_texts = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Decode error: {e}\")\n",
    "        return {\"exact_match\": 0.0}\n",
    "    \n",
    "    # Replace -100 in labels with pad token, then clip\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    labels = np.clip(labels, 0, VOCAB_SIZE - 1)\n",
    "    \n",
    "    # Decode labels\n",
    "    try:\n",
    "        label_texts = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Decode error: {e}\")\n",
    "        return {\"exact_match\": 0.0}\n",
    "    \n",
    "    # Calculate exact match\n",
    "    correct = 0\n",
    "    total = len(pred_texts)\n",
    "    \n",
    "    for pred, label in zip(pred_texts, label_texts):\n",
    "        pred_norm = re.sub(r'\\s+', ' ', pred.strip().lower())\n",
    "        label_norm = re.sub(r'\\s+', ' ', label.strip().lower())\n",
    "        if pred_norm == label_norm:\n",
    "            correct += 1\n",
    "    \n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    \n",
    "    return {\"exact_match\": accuracy}\n",
    "\n",
    "print(\"Metrics function defined (with overflow protection).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Initialize Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized!\")\n",
    "print(f\"\\nReady to train:\")\n",
    "print(f\"  Train examples: {len(tokenized['train'])}\")\n",
    "print(f\"  Validation examples: {len(tokenized['validation'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Verify Before Training\n",
    "print(\"Running verification checks...\\n\")\n",
    "\n",
    "# Test 1: Data collator\n",
    "test_batch = [tokenized['train'][i] for i in range(2)]\n",
    "try:\n",
    "    collated = data_collator(test_batch)\n",
    "    print(f\"✓ Data collator works\")\n",
    "    print(f\"  Keys: {list(collated.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Data collator failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test 2: Model forward pass\n",
    "try:\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        batch_gpu = {k: v.to(model.device) for k, v in collated.items()}\n",
    "        outputs = model(**batch_gpu)\n",
    "    print(f\"✓ Forward pass works (loss: {outputs.loss.item():.4f})\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Forward pass failed: {e}\")\n",
    "    raise\n",
    "\n",
    "# Test 3: Metrics function\n",
    "try:\n",
    "    fake_preds = np.random.randint(0, VOCAB_SIZE, (4, 20))\n",
    "    fake_labels = np.random.randint(0, VOCAB_SIZE, (4, 20))\n",
    "    metrics = compute_metrics((fake_preds, fake_labels))\n",
    "    print(f\"✓ Metrics function works\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Metrics function failed: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ALL CHECKS PASSED - READY TO TRAIN\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 13: TRAIN\n",
    "print(\"=\" * 60)\n",
    "print(\"STARTING TRAINING\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Train: {len(tokenized['train'])} examples\")\n",
    "print(f\"Epochs: {training_args.num_train_epochs}\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nThis will take 6-8 hours. You can close the browser.\\n\")\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Train!\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Train loss: {train_result.training_loss:.4f}\")\n",
    "print(f\"Time: {train_result.metrics['train_runtime']/3600:.1f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 14: Evaluate\n",
    "print(\"Running final evaluation...\\n\")\n",
    "\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Eval Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(f\"Exact Match: {eval_results['eval_exact_match']*100:.2f}%\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Grade\n",
    "em = eval_results['eval_exact_match'] * 100\n",
    "if em >= 40:\n",
    "    print(\"\\nGrade: EXCELLENT\")\n",
    "elif em >= 30:\n",
    "    print(\"\\nGrade: GOOD\")\n",
    "elif em >= 20:\n",
    "    print(\"\\nGrade: ACCEPTABLE\")\n",
    "else:\n",
    "    print(\"\\nGrade: NEEDS IMPROVEMENT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 15: Save Model\n",
    "OUTPUT_DIR = \"./text2sql_final\"\n",
    "\n",
    "print(f\"Saving model to {OUTPUT_DIR}...\")\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "\n",
    "# Save report\n",
    "report = {\n",
    "    \"team\": \"Eba Adisu, Mati Milkessa, Nahom Garefo\",\n",
    "    \"model\": MODEL_NAME,\n",
    "    \"train_examples\": len(dataset['train']),\n",
    "    \"val_examples\": len(dataset['validation']),\n",
    "    \"epochs\": training_args.num_train_epochs,\n",
    "    \"exact_match_pct\": eval_results['eval_exact_match'] * 100,\n",
    "    \"eval_loss\": eval_results['eval_loss'],\n",
    "    \"training_hours\": train_result.metrics['train_runtime'] / 3600\n",
    "}\n",
    "\n",
    "with open(\"report.json\", \"w\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(\"\\nSaved!\")\n",
    "print(\"\\nFiles to download:\")\n",
    "print(\"  1. text2sql_final/ (model)\")\n",
    "print(\"  2. report.json (metrics)\")\n",
    "print(\"  3. This notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 16: Test Inference\n",
    "from transformers import pipeline\n",
    "\n",
    "print(\"Testing inference...\\n\")\n",
    "\n",
    "generator = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=OUTPUT_DIR,\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def predict(question, schema):\n",
    "    input_text = f\"translate to SQL: {question} | schema: {schema}\"\n",
    "    result = generator(input_text, max_length=256, num_beams=4)\n",
    "    return result[0]['generated_text']\n",
    "\n",
    "# Test cases\n",
    "tests = [\n",
    "    (\"Show all students\", \"students: id, name, age, gpa\"),\n",
    "    (\"Find students with GPA above 3.5\", \"students: id, name, gpa\"),\n",
    "    (\"Count students by major\", \"students: id, name, major\"),\n",
    "    (\"What is the average salary?\", \"employees: id, name, salary\")\n",
    "]\n",
    "\n",
    "print(\"Sample predictions:\\n\")\n",
    "for q, s in tests:\n",
    "    sql = predict(q, s)\n",
    "    print(f\"Q: {q}\")\n",
    "    print(f\"SQL: {sql}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 17: Final Report\n",
    "print(\"=\" * 60)\n",
    "print(\"FINAL REPORT\")\n",
    "print(\"=\" * 60)\n",
    "print(json.dumps(report, indent=2))\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nTraining complete. Download your files and submit!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
